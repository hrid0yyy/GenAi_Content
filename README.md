# GenAi_Notebooks_By_Hrid0y

## ðŸ“˜ Project: Automatic Grader using LangChain
An **Automatic Answer Grader** using [LangChain](https://www.langchain.com/). It leverages Large Language Models (LLMs) to evaluate user responses automatically against expected answers, making it suitable for educational platforms, or quiz assessments.

### ðŸ”— Colab Notebook
[Open in Google Colab](https://colab.research.google.com/drive/1ogA1e65R8smqsWQQWiB9HShtg76QceKe?usp=sharing)


## ðŸ§  RAG vs Plain LLM Demo  
A simple demo comparing **Retrieval-Augmented Generation (RAG)** vs **plain LLM generation** to highlight the difference retrieval makes in improving responses. Asking the falcon-instruct who is Messi with and without using RAG. 

### ðŸ”— Colab Notebook  
[Open in Google Colab](https://colab.research.google.com/drive/17XH7iWg4cNnUt0nDHiMHwto63X2Moi3O?usp=sharing)


## ðŸ§  Web Scrapped RAG Demo  
A simple demo of using **Retrieval-Augmented Generation (RAG)** on web scrapped documents.

### ðŸ”— Colab Notebook  
[Open in Google Colab](https://colab.research.google.com/drive/1MSqo-6j3VmdORNWyiY78_KtFJMD2RSWT?usp=sharing)

##  [Kaggle Competition LLM Classification Finetuning](https://www.kaggle.com/competitions/llm-classification-finetuning/)
This notebook fine-tunes a DistilBERT model for LLM preference prediction, using a custom reward loss to compare response pairs. It processes training and test datasets from a Kaggle competition, generating binary preference labels (winner_model_a, winner_model_b, winner_tie) for test data.

### ðŸ”— Colab Notebook  
[Open in Google Colab](https://colab.research.google.com/drive/17xJPlIJLgCzCydKXZ75l8h8XD2jNXsVj?usp=sharing)

